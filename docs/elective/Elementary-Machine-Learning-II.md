# یادگیری ماشین مقدماتی ۲
## Elementary Machine Learning II
_______________________________________________________________________________
| نام درس:    | یادگیری ماشین مقدماتی ۲ | مقطع:       | کارشناسی      |
| ----------- | ----------------------- | ----------- | ------------- |
| پیش‌نیاز:   | ندارد                   | گروه درس:   | تخصصی اختیاری |
| هم‌نیاز:    | ندارد                   | نوع درس:    | نظری          |
| تعداد واحد: | 3                       | تعداد ساعت: | 48            |
| حل تمرین:   |  دارد                   |             |               |

**سر فصل یا رئوس مطالب**

**ماشین بردار پشتیبان** (SVM)، طبقه بندی کننده بیشینه کننده‌ی حاشیه، ابرصفحه، طبقه بندی با استفاده از یک ابرصفحه جداکننده، طبقه بند ماشین بردار پشتیبان، طبقه بندی با مرز تصمیم غیر خطی، ماشین بردار پشتیبان، مثال کاربردی برای داده های بیماری قلبی، SVM با بیش از دو کلاس، طبقه بندی یکی در مقابل همه، رابطه با رگرسیون لجستیک، منحنی های ROC، SVM، کاربرد برای داده های بیان ژن، **شبکه های عصبی** تک لایه، شبکه های عصبی چند لایه، شبکه های عصبی کانولوشنال، لایه های پیچشی، ادغام لایه ها، معماری یک شبکه عصبی کانولوشنال، افزایش داده ها، نتایج با استفاده از یک طبقه بندی کننده از پیش آموزش دیده، طبقه بندی اسناد، شبکه های عصبی برگشتی (RNN )، مدل های متوالی برای طبقه بندی اسناد، پیش بینی سری های زمانی، برازش یک شبکه عصبی، قاعده‌ی پس انتشار خطا، منظم سازی و نزول گرادیان تصادفی، تنظیم شبکه، درون یابی و نزول دوگانه، شبکه چند لایه در داده های رقمی MNIST، **یادگیری عمیق،** شبکه های عصبی پیچشی (CNN)، استفاده از مدل های CNN از پیش آموزش دیده، تجزیه و تحلیل بقا و داده های سانسور شده، زمان بقا و سانسور، منحنی بقای کاپلان مایر، آزمون Log-Rank، مدل های رگرسیون با پاسخ بقا، تابع خطر، مثال: داده های سرطان مغز، انتشارات و مرکز تماس. انقباض برای مدل کاکس، یادگیری بدون نظارت، چالش یادگیری بدون نظارت، تجزیه و تحلیل اجزای اصلی (PCA)، روش های خوشه بندی، K-Means Clustering، خوشه بندی سلسله مراتبی، مروری بر آزمون فرض، خطاهای نوع I و نوع II، چالش تست چندگانه، میزان خطای خانوادگی،‌ رویکردهایی برای کنترل میزان خطای خانوادگی، مبادله بین FWER و Power، نرخ کشف نادرست، شهود برای نرخ کشف کاذب، رویه بنجامینی-هخبرگ، رویکرد نمونه گیری مجدد برای مقادیر p و کشف نادرست نرخ ها.

**راهبردهای تدریس و یادگیری متناسب با محتوا و هدف:**

سخنرانی، در صورت نیاز شبیه‌سازی و محاسبات نرم‌افزاری، انجام تکلیف‌های محول شده توسط دانشجویان. 

پیشنهاد می‌شود به جای منابع متعدد، فقط از کتاب ISL زیر در دو درس یادگیری ماشین مقدماتی ۱ و ۲ استفاده شود. به این ترتیب دانشجویان این کتاب را به خوبی فراخواهند گرفت و آمادگی پیدا خواهند کرد که مطالب عمیق‌تر را در تحصیلات تکمیلی از کتاب ESL دنبال نمایند.

**ملزومات، تجهیزات و امکانات مورد نیاز برای ارائه:**  کلاس درس و آزمایشگاه رایانه مجهز

**فهرست منابع پیشنهادی**

1. James, G., Witten, D., Hastie, T. and Tibshirani, R. (2021). An Introduction to Statistical Learning, with applications in R, 2Ed, Springer, New York.  

([برنامه‌های کتاب فوق به زبان پایتون](https://botlnec.github.io/islp/) موجودند و گویا مولفان قصد دارند نسخه‌ی جدیدی از کتاب با پایتون در سال ۲۰۲۳ منتشر نمایند)
